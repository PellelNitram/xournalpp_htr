{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Xournal++ HTR","text":"<p>Developing handwritten text recognition for Xournal++.</p> <p>Your contributions are greatly appreciated!</p>"},{"location":"#xournal-htr-in-90-seconds","title":"Xournal++ HTR in 90 seconds","text":"(Click here to get to video on YouTube.)"},{"location":"#why-handwritten-text-recognition-for-xournal","title":"Why Handwritten Text Recognition for Xournal++?","text":"<p>A key benefit of digital note-taking is searchability, which digital handwritten notes lack without handwritten text recognition (HTR). While many commercial apps offer this feature, no open-source, privacy-focused handwriting app does - until now.</p> <p>The Xournal++ HTR project aims to bring on-device handwriting recognition to Xournal++, a leading open-source note-taking platform. This will make handwritten notes searchable while ensuring user privacy through local data processing.</p>"},{"location":"#content-of-these-websites","title":"Content of these websites","text":"<p>These websites document Xournal++ HTR. In the navigation bar, you can find instructions on how to install the project, use the project and more advanced topics like how you can contribute code and own models. In the future, many of the documents will come with small videos to get you going quicker.</p>"},{"location":"#cite","title":"Cite","text":"<p>If you are using Xournal++ HTR for your research, I'd appreciate if you could cite it. Use:</p> <pre><code>@software{Lellep_Xournalpp_HTR,\n  author = {Lellep, Martin},\n  title = {xournalpp_htr},\n  url = {https://github.com/PellelNitram/xournalpp_htr},\n  license = {GPL-2.0},\n}\n</code></pre> <p>(Also please consider starring the project on GitHub.)</p>"},{"location":"contributing/","title":"Contributing","text":"<p>There are multiple ways to contribute to this project. Below, those ways are explained alongside information on how to best contribute from a codebase point of view.</p> <p>Really, we greatly appreciate any help!</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to contribute","text":""},{"location":"contributing/#reach-out","title":"Reach out","text":"<p>If you have questions about how to best contribute or the slightest interest in contributing, then feel free to reach out to me at any time :-).</p>"},{"location":"contributing/#issues-on-github","title":"Issues on Github","text":"<p>A great way to help out with this project is to check open issues on Github and to try to work on them.</p> <p>If you need support with those, then please reach out to - we're very happy to help!</p>"},{"location":"contributing/#things-to-consider-when-contributing","title":"Things to consider when contributing","text":""},{"location":"contributing/#branching-strategy","title":"Branching strategy","text":"<p>The following branching strategy is used to keep the <code>master</code> branch stable and allow for experimentation: <code>master</code> &gt; <code>dev</code> &gt; <code>feature branches</code>. This branching strategy is shown in the following visualisation and then explained in more detail in the next paragraph:</p> <pre><code>%%{init:{  \"gitGraph\":{ \"mainBranchName\":\"master\" }}}%%\ngitGraph\n    commit\n    commit\n    branch dev\n    commit\n    checkout dev\n    commit\n    commit\n    branch feature/awesome_new_feature\n    commit\n    checkout feature/awesome_new_feature\n    commit\n    commit\n    commit\n    checkout dev\n    merge feature/awesome_new_feature\n    commit\n    commit\n    checkout master\n    merge dev\n    commit\n    commit</code></pre> <p>In more details, this repository adheres to the following git branching strategy: The <code>master</code> branch remains stable and delivers a functioning product. The <code>dev</code> branch consists of all code that will be merged to <code>master</code> eventually where the corresponding features are developed in individual feature branches; the above visualisation shows an example feature branch called <code>feature/awesome_new_feature</code> that works on a feature called <code>awesome_new_feature</code>.</p> <p>Given this structure, please implement new features as feature branches and rebase them onto the <code>dev</code> branch prior to sending a pull request to <code>dev</code>.</p> <p>Note: The Github Actions CI/CD pipeline runs on the branches <code>master</code> and <code>dev</code>.</p>"},{"location":"contributing/#code-quality","title":"Code quality","text":"<p>We try to keep up code quality as high as practically possible. For that reason, the following steps are implemented:</p> <ul> <li>Testing. Xournal++ HTR uses <code>pytest</code> for unit, regression and integration tests.</li> <li>Linting. Xournal++ HTR uses <code>ruff</code> for linting and code best practises. <code>ruff</code> is implemented as git pre-commit hook. Since <code>ruff</code> as pre-commit hook is configured externally with <code>pyproject.toml</code>, you can use the same settings in your IDE (e.g. VSCode) if you wish to speed up the process.</li> <li>Formatting. Xournal++ HTR uses <code>ruff-format</code> for consistent code formatting. <code>ruff-format</code> is implemented as git pre-commit hook. Since <code>ruff-format</code> as pre-commit hook is configured externally with <code>pyproject.toml</code>, you can use the same settings in your IDE if you wish to speed up the process.</li> </ul>"},{"location":"data_collection/","title":"Data collection and annotation","text":"(Click here to get to video on YouTube.) <p>TODO</p>"},{"location":"datasets_literature_review/","title":"Datasets literature review","text":"<p>THIS DOCUMENT IS WORK IN PROGRESS AND WILL BE COMPLETED LATER ON!</p>"},{"location":"datasets_literature_review/#draft-content","title":"Draft content","text":"<p>In this document, I am checking lit rev for datasets to know what is around and what might need to be created for best performing models.</p> <p>TODO - Now it gets messy:</p> <ul> <li>See https://chatgpt.com/c/68037a32-e49c-8009-9629-c9d38404e42b</li> <li>https://github.com/rafaeljcdarce/HWR</li> <li>https://martin-thoma.com/write-math/</li> <li>(ask him) Data: The data can be downloaded from write-math.com/data. I will try to keep a relatively recent version online. You can contact me if you want the latest version. However, I should note that currently (2015-04-12) this is about 3.7GB. This means sharing the data is not that easy.</li> <li>this seems to be constrained to single (latex) symbols; this conclusion is based on those presentations:<ul> <li>https://raw.githubusercontent.com/MartinThoma/LaTeX-examples/refs/heads/master/presentations/Bachelor-Short/LaTeX/bachelor-short.pdf</li> <li>interesting ideas: https://raw.githubusercontent.com/MartinThoma/LaTeX-examples/refs/heads/master/presentations/Bachelor-Final-Presentation/LaTeX/Bachelor-Final-Presentation.pdf</li> </ul> </li> <li>similar to: https://detexify.kirelabs.org/classify.html</li> <li>ask him about write-math.com; https://martin-thoma.com/write-math/#data</li> <li>https://arxiv.org/abs/1511.09030</li> <li>https://hwrt.readthedocs.io/</li> <li>https://github.com/MartinThoma/hwr-experiments</li> <li>https://hwrt.readthedocs.io/index.html</li> <li>! https://www.reddit.com/r/selfhosted/comments/1doy32j/document_scanning_ocr_that_works_well_with/<ul> <li>https://www.reddit.com/r/computervision/comments/15er2y7/2023_review_of_tools_for_handwritten_text/</li> </ul> </li> <li>https://detexify.kirelabs.org/classify.html</li> <li>https://github.com/kirel/detexify-data</li> </ul>"},{"location":"developer_guide/","title":"Developer Guide","text":""},{"location":"developer_guide/#project-design","title":"Project design","text":"<p>The design of Xournal++ HTR tries to bridge the gap between both delivering a production ready product and allowing contributors to experiment with new algorithms.</p> <p>The project design involves a Lua plugin and a Python backend, see the following figure. First, the production ready product is delivered by means of an Xournal++ plugin. The plugin is fully integrated in Xournal++ and calls a Python backend that performs the actual transcription. The Python backend allows selection of various recognition models and is thereby fully extendable with new models.</p> <pre><code>sequenceDiagram\n    User in Xpp--&gt;&gt;Xpp HTR Plugin: starts transcription process using currently open file\n    Xpp HTR Plugin --&gt;&gt; Xpp HTR Lua Plugin: calls\n    Xpp HTR Lua Plugin --&gt;&gt;Xpp HTR Python Backend: constructs command using CLI\n    Xpp HTR Python Backend --&gt;&gt; Xpp HTR Python Backend: Does OCR &amp; stores PDF\n    Xpp HTR Python Backend--&gt;&gt;User in Xpp: Gives back control to UI</code></pre> <p>Developing a usable HTR systems requires experimentation. The project structure is set up to accommodate this need. Note that ideas on improved project structures are appreciated.</p> <p>The experimentation is carried out in terms of \"concepts\". Each concept explores a different approach to HTR and possibly improves over previous concepts, but not necessarily to allow for freedom in risky experiments. Concept 1 is already implemented and uses a computer vision approach that is explained below.</p> <p>Future concepts might explore:</p> <ul> <li>Retrain computer vision models from concept 1 using native online data representation of Xournal++</li> <li>Use sequence-to-sequence models to take advantage of native online data representation of Xournal++; e.g. use OnlineHTR</li> <li>Use data augmentation to increase effective size of training data</li> <li>Use of language models to correct for spelling mistakes</li> </ul>"},{"location":"developer_guide/#concept-1","title":"Concept 1","text":"<p>This concept uses computer vision based algorithms to first detect words on a page and then to read those words.</p> <p>The following shows a video demo on YouTube using real-life handwriting data from a Xournal file:</p> <p></p> <p>Despite not being perfect, the main take away is that the performance is surprisingly good given that the underlying algorithm has not been optimised for Xournal++ data at all.</p> <p>The performance is sufficiently good to be useful for the Xournal++ user base.</p> <p>Feel free to play around with the demo yourself using this code after installing this project. The \"concept 1\" is also what is currently used in the plugin and shown in the 90 seconds demo.</p> <p>Next steps to improve the performance of the handwritten text recognition even further could be:</p> <ul> <li>Re-train the algorithm on Xournal++ specific data, while potentially using data augmentation.</li> <li>Use language model to improve text encoding.</li> <li>Use sequence-to-sequence algorithm that makes use of Xournal++'s data format. This translates into using online HTR algorithms.</li> </ul> <p>I would like to acknowledge Harald Scheidl in this concept as he wrote the underlying algorithms and made them easily usable through his HTRPipeline repository - after all I just feed his algorithm Xournal++ data in concept 1. Go check out his great content!</p>"},{"location":"developing_new_models/","title":"Developing new models","text":"(Click here to get to video on YouTube.) <ul> <li>I provide dataset and code to experiment w/ new models</li> <li>train both your own bespoke and general models.</li> </ul>"},{"location":"developing_new_models/#training","title":"Training","text":""},{"location":"developing_new_models/#installation","title":"Installation","text":"<p>Follow the above installation procedure and replace the step <code>pip install -r requirements.txt</code> by both <code>pip install -r requirements.txt</code> and <code>pip install -r requirements_training.txt</code> to install both the inference and training dependencies.</p>"},{"location":"funding/","title":"Funding","text":"<p>This project is mostly a solo project and I love to work on it (please contribute, if you want to - happy to help along the way!).</p> <p>However, it is both a large time commitment and requires compute resources for training models.</p> <p>If you think this project is valuable and want to express your gratitute, then please feel free to buy me a virtual coffee here :-).</p> <p>Thanks!!</p>"},{"location":"huggingface_docker_space_deployment/","title":"Huggingface docker space deployment","text":""},{"location":"huggingface_docker_space_deployment/#local-docker-image-building","title":"Local Docker image building","text":"<ol> <li>Build the Docker image: <code>docker build -t xournalpp_htr .</code></li> <li>Run Docker image: <code>docker run -d -p 7860:7860 xournalpp_htr</code><ul> <li>Interactively for debugging: <code>docker run -it --entrypoint bash xournalpp_htr</code></li> </ul> </li> <li>Run Docker image for interactive development<ul> <li>Start docker container: <code>docker run -it -p 7860:7860 -v $(pwd):/temp_code_mount --entrypoint bash xournalpp_htr</code></li> <li>Call Python code inside the container: <code>python /temp_code_mount/scripts/demo.py</code></li> </ul> </li> </ol> <p>Generally, tidy up Docker caches with <code>docker system prune</code> if your system is full.</p>"},{"location":"huggingface_docker_space_deployment/#looking-into-adding-xournalpp-to-the-image-bc-i-need-that-for-the-prediction-to-convert-xojxopp-to-pdf","title":"looking into adding xournalpp to the image b/c i need that for the prediction (to convert xoj/xopp to pdf):","text":"<p>now cross compiled on M4 - build image: <code>docker buildx build --platform linux/amd64 -t xournalpp_htr .</code> - interactively entering: <code>docker run -it --platform linux/amd64 -p 7860:7860 -v $(pwd):/temp_code_mount --entrypoint bash xournalpp_htr</code> - dl deb file: <code>wget --no-check-certificate https://github.com/xournalpp/xournalpp/releases/download/v1.2.8/xournalpp-1.2.8-Debian-bookworm-x86_64.deb</code>     - there're issues!! - alternative: use appimage:     - <code>wget --no-check-certificate https://github.com/xournalpp/xournalpp/releases/download/v1.2.8/xournalpp-1.2.8-x86_64.AppImage</code></p>"},{"location":"huggingface_docker_space_deployment/#commands-to-set-up-supabase-for-event-logging-and-data-storage","title":"Commands to set up Supabase for event logging and data storage","text":"<p>Contents of <code>.env</code> file:</p> <pre><code>DEMO=1\nSB_URL=\"https://&lt;add here&gt;.supabase.co\"\nSB_KEY=\"&lt;add here&gt;\"\nSB_BUCKET_NAME=\"xournalpp_htr_hf_space\"\nSB_SCHEMA_NAME=\"public\"\nSB_TABLE_NAME=\"xournalpp_htr_hf_space_events\"\n</code></pre> <p>Create the events table:</p> <pre><code>create table public.xournalpp_htr_hf_space_events (\n  id bigserial primary key,\n  timestamp timestamptz not null,\n  demo boolean not null,\n  session_id text not null,\n  donate_data bool not null,\n  interaction text not null\n);\n</code></pre> <p>Create bucket:</p> <pre><code>xournalpp_htr_hf_space\n</code></pre>"},{"location":"installation_developer/","title":"Development installation","text":"<ol> <li>Perform the same installation steps as described in the user installation manual.</li> <li>Then, install developer dependencies: <code>pip install -r requirements_training.txt</code>.</li> </ol> <p>Depending on your needs, it is probably worth creating a dedicated Python environment for development. To do so, simply change <code>xournalpp_htr</code> from user installation manual to another name like <code>xournalpp_htr_dev</code> when you follow the above development installation steps.</p>"},{"location":"installation_user/","title":"Installation","text":"<p>This project consists of both the inference and training code. Most users will only be interested in the inference part, so that the below only comprises of the inference part that you need to execute the plugin from within Xournal++.</p> <p>The training part is optional and allows to help to train our own models which improve over time. This installation process is optional and detailed in the developer guide.</p>"},{"location":"installation_user/#linux","title":"Linux","text":"<p>Run <code>bash INSTALL_LINUX.sh</code> from repository root directory.</p> <p>This script also installs the plugin as explained in the last point of the cross-platform installation procedure. The installation of the plugin is performed with <code>plugin/copy_to_plugin_folder.sh</code>, which can also be invoked independently of <code>INSTALL_LINUX.sh</code> for updating the plugin installation.</p>"},{"location":"installation_user/#cross-platform","title":"Cross-platform","text":"<p>If you want to install the plugin manually, then execute the following commands:</p> <ol> <li>Create an environment: <code>conda create --name xournalpp_htr python=3.10.11</code>.</li> <li>Use this environment: <code>conda activate xournalpp_htr</code>.</li> <li>Install HTRPipelines package using its installation guide.</li> <li>Install all dependencies of this package <code>pip install -r requirements.txt</code>.</li> <li>Install the package in development mode with <code>pip install -e .</code> (do not forget the dot, '.').</li> <li>Install pre-commit hooks with: <code>pre-commit install</code>.</li> <li>Copy <code>plugin/</code> folder content to <code>${XOURNAL_CONFIG_PATH}/plugins/xournalpp_htr/</code> with <code>${XOURNAL_CONFIG_PATH}</code> being the configuration path of Xournal++, see Xournal++ manual here.</li> <li>Edit <code>config.lua</code>, setting <code>_M.python_executable</code> to your python executable in the conda environment and <code>_M.xournalpp_htr_path</code> to the absolute path of this repo. See the example config for details in <code>plugin/config.lua</code>.</li> <li>Ensure Xournal++ is on your <code>PATH</code>. See here for the binary location.</li> </ol>"},{"location":"installation_user/#after-installation","title":"After installation","text":"<p>Confirm that the installation worked by running <code>make tests-installation</code> from repository root directory.</p>"},{"location":"pyinstaller_experiment/","title":"TODO!","text":""},{"location":"pyinstaller_experiment/#pyinstaller-experiment","title":"PyInstaller Experiment","text":"<p>For easier installation.</p> <p>Scope: On Linux.</p> <p>Commands I experimented with:</p> <pre><code>cd xournalpp_htr\npyinstaller --onefile --add-data \"../external/htr_pipeline/HTRPipeline/htr_pipeline/models:htr_pipeline/models\" --hidden-import \"PIL._tkinter_finder\" run_htr.py\ndist/run_htr --input-file /home/martin/data/xournalpp_htr/test_1.xoj --output-file /home/martin/Development/xournalpp_htr/tests/test_1_from_Xpp-3.pdf\n</code></pre> <p>This seems to work on my Ubuntu PC.</p> <p>Open questions: - Does it work on other linux computers?     - Idea: check w/ EC2/GCP-VM instances. - How to include the <code>xournalpp</code> binary in order to export the <code>xopp</code> file to a PDF?     - Idea: Let the use select the <code>xournalpp</code> path?</p>"},{"location":"roadmap/","title":"Roadmap","text":"<p>On this page, we outline the project's intended roadmap. This plan helps us strategically manage our time and resources.</p> <p>Below, we present our roadmap. It may evolve over time, so we will preserve previous versions to maintain transparency.</p>"},{"location":"roadmap/#roadmap-as-of-2025-05-03","title":"Roadmap as of 2025-05-03","text":""},{"location":"roadmap/#visual-overview","title":"Visual Overview","text":"<pre><code>flowchart LR\n    A0(\n        Conduct\n        dataset\n        research\n    )\n    A(\n        Reimplement\n        &lt;a href=\"https://github.com/githubharald/HTRPipeline\"&gt;htr_pipeline&lt;/a&gt;\n    )\n    B(\n        Classic algos w\n        &lt;a href=\"https://github.com/PellelNitram/OnlineHTR\"&gt;OnlineHTR&lt;/a&gt;\n    )\n    C(\n        Start own\n        modeling\n    )\n    D(\n        Introduce\n        quality\n        measures\n    )\n    E(\n        Graph NN w\n        &lt;a href=\"https://github.com/PellelNitram/OnlineHTR\"&gt;OnlineHTR&lt;/a&gt;\n    )\n    F(\n        Make\n        installation\n        easier\n    )\n    G(\n        Explore offline\n        recognition models\n        like &lt;a href=\"https://arxiv.org/abs/1904.01941\"&gt;CRAFT&lt;/a&gt;\n    )\n    A --&gt; F\n    F --&gt; D\n    D --&gt; A0\n    A0 --&gt; C\n    C --&gt; B\n    C --&gt; E\n    C --&gt; G</code></pre>"},{"location":"roadmap/#explanation","title":"Explanation","text":"<p>This project has many potential directions, with the primary goal of delivering optimal value to users. While we are eager to implement advanced machine learning algorithms, we must first focus on usability improvements.</p> <p>Our main mid-term objective is to simplify the installation process, as users have reported it is too complex.</p> <p>Explanation of the steps:</p> <ul> <li> <p>Reimplement htr_pipeline:   We currently use the excellent htr_pipeline by Harald Scheidl for machine learning, but it being an external dependency complicates installation and them hosting model weights on Dropbox is not suitable for our needs. To address this, we plan to integrate these models directly into our project. Since the original repository lacks a license, we'll implement our own version, drawing inspiration from the existing work. This approach will deliver an easy-to-install product quickly, as we already know the requirements &amp; model details. Additionally, it enhances our understanding of training models for both online and offline handwriting data. With our own models, we'll automate model retrieval and establish a model registry, likely using Hugging Face, as part of adhering to MLOps best practices. Experimentation with new algorithms will benefit from the model registry and will occur subsequently, as it is more time-consuming.</p> </li> <li> <p>Make installation easier:   We aim to make the installation process seamless across platforms, including Linux and Windows, with future support for Mac if access becomes available to us. Implementing a model registry will streamline model management and deployment, aiding future model development and enhancing ease of use while aligning with best practices.</p> </li> <li> <p>Introduce quality measures:   To identify the best model, we need to quantify performance. Ideally, one metric will suffice, but two may be necessary if recognition and transcription remain separate tasks.</p> </li> <li> <p>Classic algos w OnlineHTR:   The plan is to use OnlineHTR for transcription alongside classical (non-data-driven) algorithms for recognition.</p> </li> <li> <p>Graph NN w OnlineHTR:   We aim to use OnlineHTR for transcription and a graph neural network for recognition. This approach seeks to develop a high-performing model that operates on the native online representation of handwriting.</p> </li> </ul>"},{"location":"user_guide/","title":"Usage","text":"<p>The usage of the project is fairly simple. First, there is a Python script that performs the actual work &amp; is useful for headless operations like batch processing. Second, and probably much more useful for the average user, the Lua plugin can be used from within Xournal++ and invokes the aforementioned Python script under the hood.</p>"},{"location":"user_guide/#the-lua-plugin","title":"The Lua plugin","text":"<p>Details relevant for usage of the Lua plugin:</p> <ol> <li>Make sure to save your file in Xournal++ beforehand. The plugin will also let you know that you need to save your file first.</li> <li>After installation, navigate to <code>Plugin &gt; Xournal++ HTR</code> to invoke the plugin. Then select a filename and press <code>Save</code>. Lastly, wait a wee bit until the process is finished; the Xournal++ UI will block while the plugin applies HTR to your file. If you opened Xournal++ through a command-line, you can see progress bars that show the HTR process in real-time.</li> </ol> <p>Note: Currently, the Xournal++ HTR plugin requires you to use a nightly build of Xournal++ because it uses upstream Lua API features that are not yet part of the stable build. Using the officially provided Nightly AppImag, see here, is very convenient. The plugin has been tested with the following nightly Linux build of Xournal++:</p> <pre><code>xournalpp 1.2.3+dev (583a4e47)\n\u2514\u2500\u2500libgtk: 3.24.20\n</code></pre>"},{"location":"user_guide/#the-python-script","title":"The Python script","text":"<p>It is located in <code>xournalpp_htr/run_htr.py</code> and it features a command line interface that documents the usage of the Python script.</p>"},{"location":"ADRs/2025-10-04_design_of_huggingface_space_dockerfile/","title":"Design of HuggingFace Space Dockerfile","text":"<ul> <li>Status: Ongoing</li> <li>Deciders: Martin Lellep (@PellelNitram)</li> <li>Drivers: Martin Lellep (@PellelNitram)</li> <li>PRD: None</li> <li>Date: 2025-10-04</li> </ul>"},{"location":"ADRs/2025-10-04_design_of_huggingface_space_dockerfile/#context","title":"Context","text":"<p>Explain the background and the context in which the decision is being made. Include any relevant information about the problem, constraints, or goals.</p>"},{"location":"ADRs/2025-10-04_design_of_huggingface_space_dockerfile/#decisions","title":"Decisions","text":"<p>State the decision that has been made. Be clear and concise.</p> <ul> <li>In the future, download models at build time into the Docker image from Github release page. In the   very far future, pull them from HuggingFace at run-time.</li> <li>Add <code>xournalpp</code> binary to Docker image so that the <code>xopp</code> file can be exported as PDF prior to   execution of the HTR pipeline.</li> </ul>"},{"location":"ADRs/2025-10-04_design_of_huggingface_space_dockerfile/#consequences","title":"Consequences","text":"<p>Describe the consequences of the decision. Include both positive and negative outcomes, as well as any trade-offs.</p>"},{"location":"ADRs/2025-10-04_design_of_huggingface_space_dockerfile/#alternatives-considered","title":"Alternatives Considered","text":"<p>List and briefly describe other options that were considered and why they were not chosen.</p>"},{"location":"ADRs/2025-10-04_design_of_huggingface_space_dockerfile/#references","title":"References","text":"<p>Include links or references to any supporting documentation, discussions, or resources.</p>"},{"location":"images/TODO/","title":"TODO","text":"<ul> <li>Add 90s qiuckstart video and document.</li> </ul>"}]}