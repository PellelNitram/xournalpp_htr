{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539c5c9b",
   "metadata": {},
   "source": [
    "# Run Training\n",
    "\n",
    "This notebook trains the neural network and serves as starting point to move the training into a separate Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb9aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from my_code import IAM_Dataset\n",
    "from my_code import ImageDimensions\n",
    "from my_code import custom_collate_fn\n",
    "from my_code import count_parameters\n",
    "from my_code import fg_by_cc\n",
    "from my_code import cluster_aabbs\n",
    "from my_code import binary_classification_metrics\n",
    "from my_code import draw_bboxes_on_image\n",
    "from my_code import MapOrdering\n",
    "from my_code import encode, decode, BoundingBox, ImageDimensions\n",
    "from my_code import ModifiedResNet18\n",
    "from my_code import WordDetectorNet\n",
    "from my_code import compute_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec9d596",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f6c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "device = 'cuda'\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "val_epoch = 5\n",
    "val_epoch = 1\n",
    "\n",
    "summary_writer_path = Path.home() / 'summary_writer_path'\n",
    "\n",
    "epoch_max = 100 # Simulate full training\n",
    "# epoch_max = 10\n",
    "# epoch_max = 0\n",
    "epoch_max = 3\n",
    "# epoch_max = 10000\n",
    "\n",
    "patience_max = 50\n",
    "\n",
    "# Dataset settings\n",
    "data_path = Path.home() / 'Development/WordDetectorNN/data/train'\n",
    "percent_train_data = 80\n",
    "input_size = ImageDimensions(width=448, height=448) # TODO: Use below\n",
    "output_size = ImageDimensions(width=224, height=224) # TODO: Use below\n",
    "\n",
    "# Dataloader settings\n",
    "shuffle_data_loader = True\n",
    "batch_size = 32\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16678646",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I copied the code from above\n",
    "\n",
    "# -- datasets --\n",
    "\n",
    "# Create datasets with different transforms\n",
    "train_transform = None\n",
    "val_transform = None\n",
    "# TODO: ^ Implement the augmentations, w/ each changing at every batch\n",
    "\n",
    "train_dataset = IAM_Dataset(\n",
    "    root_dir=data_path,\n",
    "    input_size=ImageDimensions(width=448, height=448),\n",
    "    output_size=ImageDimensions(width=224, height=224),\n",
    "    force_rebuild_cache=True,\n",
    "    transform=train_transform,\n",
    ")\n",
    "val_dataset = IAM_Dataset(\n",
    "    root_dir=data_path,\n",
    "    input_size=ImageDimensions(width=448, height=448),\n",
    "    output_size=ImageDimensions(width=224, height=224),\n",
    "    force_rebuild_cache=True,\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "assert len(train_dataset) == len(val_dataset)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "split = int(percent_train_data / 100 * len(indices))\n",
    "\n",
    "train_indices = indices[:split]\n",
    "val_indices = indices[split:]\n",
    "\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(val_dataset, val_indices)\n",
    "\n",
    "train_filenames = [sample['filename'] for sample in train_subset]\n",
    "val_filenames = [sample['filename'] for sample in val_subset]\n",
    "# Check that no train samples are in val\n",
    "assert len(set(train_filenames + val_filenames)) == len(train_filenames) + len(val_filenames)\n",
    "\n",
    "assert len(dataset) == len(train_subset) + len(val_subset)\n",
    "\n",
    "# -- dataloaders --\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_data_loader,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=custom_collate_fn,  # or custom_collate_fn_with_padding\n",
    "    pin_memory=True  # For faster GPU transfer\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False, # no need to shuffle validation data and otherwise images break\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=custom_collate_fn,  # or custom_collate_fn_with_padding\n",
    "    pin_memory=True  # For faster GPU transfer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972310c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(summary_writer_path / datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\"))\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "def train(net, optimizer, loader, writer):\n",
    "    global global_step\n",
    "\n",
    "    net.train()\n",
    "    for i, loader_item in enumerate(loader):\n",
    "\n",
    "        images = loader_item['images']\n",
    "        gt_encoded = loader_item['gt_encoded']\n",
    "\n",
    "        images = images.to(device)\n",
    "        gt_encoded = gt_encoded.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y = net(images)\n",
    "        loss = compute_loss(y, gt_encoded)\n",
    "\n",
    "        # backward pass, optimize loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # output\n",
    "        print(f'{i + 1}/{len(loader)}: {loss.item()}')\n",
    "        writer.add_scalar('loss/train', loss, global_step)\n",
    "        global_step += 1\n",
    "\n",
    "REGULARISATION = 1e-8\n",
    "\n",
    "# TODO: Even w/o benchmarking, I can say that this is the bottleneck here. Also, it's\n",
    "#       not the GPU part that is the bottleneck, but the CPU part. How about making\n",
    "#       the loop annotated with (A) run in parallel?\n",
    "def validate(net, dataloader_val, writer):\n",
    "    global global_step\n",
    "    net.eval()\n",
    "    avg_loss = 0.0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    image_counter = 0\n",
    "    for i, batch in enumerate(dataloader_val):\n",
    "        # For loss\n",
    "        with torch.no_grad():\n",
    "            images = batch['images']\n",
    "            gt_encoded = batch['gt_encoded']\n",
    "            images = images.to(device)\n",
    "            gt_encoded = gt_encoded.to(device)\n",
    "            y = net(images)\n",
    "            loss = compute_loss(y, gt_encoded)\n",
    "            avg_loss += loss.item()\n",
    "        # For metrics; TODO: Can be combined by performing softmax on y from above but too lazy right now\n",
    "        with torch.no_grad():\n",
    "            images = batch['images']\n",
    "            gt_encoded = batch['gt_encoded']\n",
    "            images = images.to(device)\n",
    "            gt_encoded = gt_encoded.to(device)\n",
    "            y = net(images, apply_softmax=True)\n",
    "            assert y[:, MapOrdering.SEG_WORD:MapOrdering.SEG_BACKGROUND+1, :, :].min() >= 0.0\n",
    "            assert y[:, MapOrdering.SEG_WORD:MapOrdering.SEG_BACKGROUND+1, :, :].max() <= 1.0\n",
    "        batch_size_here = y.shape[0]\n",
    "        y = y.to('cpu').numpy()\n",
    "        for i_element_in_batch in range(batch_size_here): # <-- (A)\n",
    "            y_element = y[i_element_in_batch, :, :, :]\n",
    "            decoded_aabbs = decode(y_element, scale=input_size.width / output_size.width, comp_fg=fg_by_cc(thres=0.5, max_num=1000))\n",
    "            img_np = batch['images'][i_element_in_batch, 0, :, :].to('cpu').numpy()\n",
    "            h, w = img_np.shape\n",
    "            aabbs = [aabb.clip(BoundingBox(0, 0, w - 1, h - 1)) for aabb in decoded_aabbs]  # bounding box must be inside img\n",
    "            clustered_aabbs = cluster_aabbs(aabbs)\n",
    "            result = binary_classification_metrics(batch['bounding_boxes'][i_element_in_batch], clustered_aabbs)\n",
    "            tp += result['tp']\n",
    "            fp += result['fp']\n",
    "            fn += result['fn']\n",
    "            vis = draw_bboxes_on_image(img_np, clustered_aabbs)\n",
    "            writer.add_image(f'img{image_counter}', vis.transpose((2, 0, 1)), global_step)\n",
    "            image_counter += 1\n",
    "    avg_loss = avg_loss / len(dataloader_val)\n",
    "    precision = tp / (tp + fp + REGULARISATION)\n",
    "    recall = tp / (tp + fn + REGULARISATION)\n",
    "    f1 = 2*precision*recall / (precision + recall + REGULARISATION)\n",
    "    writer.add_scalar('loss/val', avg_loss, global_step)\n",
    "    writer.add_scalar('f1/val', f1, global_step)\n",
    "    return f1\n",
    "\n",
    "net = WordDetectorNet()\n",
    "net.to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# main training loop\n",
    "epoch = 0\n",
    "best_val_f1 = 0.0\n",
    "patience_counter = 0\n",
    "while True:\n",
    "    epoch += 1\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train(net, optimizer, dataloader_train, writer)\n",
    "    if epoch % val_epoch == 0:\n",
    "        f1 = validate(net, dataloader_val, writer)\n",
    "\n",
    "        if f1 > best_val_f1:\n",
    "            print(f\"New best F1 score: {best_val_f1:.4f} -> {f1:.4f}, saving model.\")\n",
    "            best_val_f1 = f1\n",
    "            torch.save(net.state_dict(), 'best_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience_max:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    if epoch >= epoch_max:\n",
    "        print(f\"Reached max epoch {epoch_max}, stopping training.\")\n",
    "        break\n",
    "\n",
    "writer.add_hparams(\n",
    "    {\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "        # TODO: Add seed in order to be able to run multiple seeds\n",
    "    },\n",
    "    {\n",
    "        'best_val_f1': best_val_f1,\n",
    "    }\n",
    ")\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# TODO: Later, replace all print statements w/ proper logging statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d87f23",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd45dc",
   "metadata": {},
   "source": [
    "Let's check how the predicted maps look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a755d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "avg_loss = 0.0\n",
    "batch = next(iter(dataloader_val))\n",
    "with torch.no_grad():\n",
    "    images = batch['images']\n",
    "    gt_encoded = batch['gt_encoded']\n",
    "    images = images.to(device)\n",
    "    gt_encoded = gt_encoded.to(device)\n",
    "    y = net(images, apply_softmax=True)\n",
    "    # loss = compute_loss(y, gt_encoded) # Not compatible w/ y if apply_softmax=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24701a6",
   "metadata": {},
   "source": [
    "Let's look at the prediction of inner words pixels because that is used for bounding box computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cddaf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_element_in_batch = 12\n",
    "prediction = y[i_element_in_batch, MapOrdering.SEG_WORD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b936017",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = batch['gt_encoded'][i_element_in_batch, MapOrdering.SEG_WORD].cpu().numpy()\n",
    "pred = prediction.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Prediction\")\n",
    "plt.imshow(pred > 0.5, cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.imshow(gt, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c372f4",
   "metadata": {},
   "source": [
    "Very interesting, that looks actually quite good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
